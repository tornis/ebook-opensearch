# CAP√çTULO 2: CONCEITOS FUNDAMENTAIS

## 2. CONCEITOS FUNDAMENTAIS

### Objetivos de Aprendizagem

Ao final deste cap√≠tulo, voc√™ ser√° capaz de:

1. Compreender a estrutura hier√°rquica de √≠ndices, documentos e tipos de dados no OpenSearch
2. Implementar mapeamentos din√¢micos e expl√≠citos para estrutura√ß√£o de dados
3. Aplicar analyzers e tokeniza√ß√£o para otimizar buscas textuais
4. Explicar o funcionamento do inverted index e suas estruturas internas
5. Executar opera√ß√µes CRUD completas via API REST do OpenSearch

---

## 2.1 FUNDA√á√ïES: √çNDICES, DOCUMENTOS E TIPOS DE DADOS

### Introdu√ß√£o Conceitual

O OpenSearch organiza dados em uma hierarquia bem definida: **cluster** ‚Üí **√≠ndice** ‚Üí **documento** ‚Üí **campo**. Compreender essa estrutura √© fundamental para trabalhar efetivamente com a plataforma, pois determina como os dados s√£o armazenados, indexados e recuperados.

Diferentemente de bancos de dados relacionais tradicionais, onde voc√™ trabalha com tabelas e registros, o OpenSearch utiliza um modelo baseado em **documentos JSON** armazenados em **√≠ndices**. Essa abordagem oferece flexibilidade estrutural e escalabilidade horizontal, permitindo buscas ultra-r√°pidas em volumes massivos de dados.

### 2.1.1 √çndices: O Contenedor de Dados

Um **√≠ndice** no OpenSearch √© a unidade b√°sica de armazenamento e representa um conjunto l√≥gico de documentos relacionados. Voc√™ pode pensar em um √≠ndice como equivalente a uma tabela em um banco de dados relacional, mas com capacidades muito mais robustas de busca.

**Caracter√≠sticas principais de um √≠ndice:**

- **Distribu√≠do**: Os dados s√£o divididos em shards (fragmentos) distribu√≠dos entre m√∫ltiplos n√≥s
- **Replic√°vel**: Cada shard possui r√©plicas para alta disponibilidade
- **Versionado**: Suporta controle de vers√£o autom√°tico de documentos
- **Mape√°vel**: Possui um schema flex√≠vel que pode ser definido ou evoluir dinamicamente

Um √≠ndice √© identificado por um **nome √∫nico** no cluster. Por conven√ß√£o, os nomes devem seguir padr√µes como: `logs-aplicacao-2025`, `produtos-ecommerce`, `usuarios-ativa`.

**Arquitetura hier√°rquica de um √≠ndice:**

```mermaid
graph TD
    A["Cluster OpenSearch"] --> B["√çndice: logs-api-2025"]
    B --> C["Shard 0<br/>Prim√°rio<br/>N√≥ 1"]
    B --> D["Shard 1<br/>Prim√°rio<br/>N√≥ 2"]
    B --> E["Shard 2<br/>Prim√°rio<br/>N√≥ 3"]
    
    C --> C1["Doc 1<br/>Doc 3<br/>Doc 6"]
    C --> C2["R√©plica<br/>N√≥ 4"]
    
    D --> D1["Doc 2<br/>Doc 5<br/>Doc 8"]
    D --> D2["R√©plica<br/>N√≥ 5"]
    
    E --> E1["Doc 4<br/>Doc 7<br/>Doc 9"]
    E --> E2["R√©plica<br/>N√≥ 6"]
    
    style A fill:#e1f5ff
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#81d4fa
    style E fill:#81d4fa
    style C2 fill:#ffccbc
    style D2 fill:#ffccbc
    style E2 fill:#ffccbc
```

### 2.1.2 Documentos: Registros de Dados

Um **documento** √© a unidade fundamental de dados no OpenSearch. Trata-se de um objeto JSON que cont√©m dados estruturados ou semi-estruturados associados a um identificador √∫nico (\_id).

**Estrutura e composi√ß√£o de um documento:**

```mermaid
graph LR
    A["Documento JSON"] --> B["Metadados"]
    A --> C["Dados"]
    
    B --> B1["_id"]
    B --> B2["_index"]
    B --> B3["_type"]
    B --> B4["_version"]
    B --> B5["_score"]
    
    C --> C1["_source"]
    C1 --> C1A["campo1"]
    C1 --> C1B["campo2"]
    C1 --> C1C["...campoN"]
```

**Exemplo de documento completo:**

```json
{
  "_id": "12345",
  "_index": "produtos-ecommerce",
  "_type": "_doc",
  "_version": 1,
  "_score": 1.0,
  "_source": {
    "nome": "Notebook Dell XPS 13",
    "preco": 4500.00,
    "categoria": "Eletr√¥nicos",
    "estoque": 25,
    "descricao": "Notebook ultraport√°til com processador Intel Core i7",
    "criado_em": "2025-01-10T14:30:00Z",
    "ativo": true
  }
}
```

**Campos de metadados:**

- **\_id**: Identificador √∫nico do documento. Pode ser gerado automaticamente ou definido pelo usu√°rio
- **\_index**: Nome do √≠ndice ao qual o documento pertence
- **\_type**: Tipo do documento (no OpenSearch 2.0+, sempre \_doc)
- **\_version**: N√∫mero de vers√£o do documento (incrementado a cada modifica√ß√£o)
- **\_score**: Relev√¢ncia do documento em uma busca (presente apenas em resultados de queries)
- **\_source**: Dados reais do documento em formato JSON

### 2.1.3 Tipos de Dados Suportados

O OpenSearch suporta diversos tipos de dados nativamente. A correta escolha de tipos impacta diretamente em performance, armazenamento e capacidades de busca.

**Categoriza√ß√£o de tipos de dados:**

```mermaid
graph TD
    A["Tipos de Dados<br/>OpenSearch"] --> B["Primitivos"]
    A --> C["Textuais"]
    A --> D["Num√©ricos"]
    A --> E["Temporais"]
    A --> F["Geoespaciais"]
    A --> G["Complexos"]
    
    B --> B1["boolean"]
    
    C --> C1["text"]
    C --> C2["keyword"]
    
    D --> D1["integer, long"]
    D --> D2["float, double"]
    
    E --> E1["date"]
    
    F --> F1["geo_point"]
    F --> F2["geo_shape"]
    
    G --> G1["object"]
    G --> G2["nested"]
    G --> G3["array"]
    
    style B1 fill:#ffccbc
    style C1 fill:#c8e6c9
    style C2 fill:#c8e6c9
    style D1 fill:#bbdefb
    style D2 fill:#bbdefb
    style E1 fill:#f8bbd0
    style F1 fill:#fff9c4
    style F2 fill:#fff9c4
    style G1 fill:#e1bee7
    style G2 fill:#e1bee7
    style G3 fill:#e1bee7
```

**Tipos de dados primitivos:**

| Tipo | Descri√ß√£o | Exemplo |
|------|-----------|---------|
| text | Texto completo, analisado para buscas | "O r√°pido raposa marrom" |
| keyword | Texto exato, n√£o analisado | "eletr√¥nicos", "ativo" |
| integer | N√∫mero inteiro | 42, -100 |
| long | N√∫mero inteiro grande | 9223372036854775807 |
| float | N√∫mero decimal | 3.14, 99.99 |
| double | N√∫mero decimal de alta precis√£o | 2.718281828 |
| boolean | Verdadeiro/Falso | true, false |
| date | Data e hora ISO 8601 | "2025-01-15T10:30:00Z" |
| geo_point | Coordenadas geogr√°ficas | {"lat": -23.55, "lon": -46.63} |
| ip | Endere√ßo IP | "192.168.1.1" |

**Tipos de dados complexos:**

| Tipo | Descri√ß√£o | Uso |
|------|-----------|-----|
| object | Documento aninhado | Dados hier√°rquicos |
| nested | Array de objetos | Manter rela√ß√£o entre campos |
| keyword | Array de palavras-chave | Tags, categorias |
| text | Array de textos | Descri√ß√µes m√∫ltiplas |

---

### üìå **BOX DE DEFINI√á√ÉO: Diferen√ßa Entre text e keyword**

**text**: Campo analisado pelo analyzer padr√£o. Ideal para buscas em texto completo. Exemplo: descri√ß√µes de produtos.

**keyword**: Campo n√£o analisado, armazenado como valor exato. Ideal para filtros e agrega√ß√µes. Exemplo: status, categoria.

---

## 2.2 MAPPING: DEFININDO A ESTRUTURA DE DADOS

### Conceito e Import√¢ncia

**Mapping** √© o esquema que define como os documentos e seus campos devem ser indexados. √â an√°logo ao schema de um banco de dados relacional, mas com maior flexibilidade e capacidades de busca.

Um bom mapping √© cr√≠tico para:

- **Performance**: Tipos incorretos causam inefici√™ncia de busca
- **Precis√£o**: Determina como dados s√£o interpretados (n√∫mero vs. texto)
- **Funcionalidade**: Habilita agrega√ß√µes, sorting e an√°lises avan√ßadas
- **Armazenamento**: Otimiza espa√ßo em disco

### 2.2.1 Mapping Din√¢mico

Quando voc√™ indexa um documento sem pr√©-definir um mapping, o OpenSearch **automaticamente detecta** os tipos de campos e cria o mapping dinamicamente. Isso oferece flexibilidade mas pode levar a inconsist√™ncias.

**Processo de mapping din√¢mico vs. expl√≠cito:**

```mermaid
graph TD
    A["Novo Documento<br/>Chegando"] --> B{Existe<br/>Mapping?}
    
    B -->|N√£o| C["Mapping Din√¢mico"]
    B -->|Sim| D["Mapping Expl√≠cito"]
    
    C --> C1["OpenSearch analisa<br/>cada campo"]
    C1 --> C2["Detecta tipos"]
    C2 --> C3["Cria mapping<br/>automaticamente"]
    C3 --> C4["R√°pido<br/>Flex√≠vel<br/>Pode ter<br/>inconsist√™ncias"]
    
    D --> D1["Valida contra<br/>schema pr√©-definido"]
    D1 --> D2["Aplica tipos<br/>espec√≠ficos"]
    D2 --> D3["Rejeita se<br/>n√£o conformar"]
    D3 --> D4["Controlado<br/>Consistente<br/>Seguro"]
    
    style C4 fill:#fff9c4
    style D4 fill:#c8e6c9
```

**Exemplo: Criando um √≠ndice e adicionando documento sem mapping pr√©vio**

```bash
# Requisi√ß√£o HTTP POST
POST http://localhost:9200/produtos-dinamico/_doc
Content-Type: application/json

{
  "nome": "Mouse Logitech MX Master 3",
  "preco": 350.00,
  "em_estoque": true,
  "tags": ["perif√©rico", "wireless"],
  "criado_em": "2025-01-15T10:30:00Z"
}
```

O OpenSearch automaticamente cria o mapping:

```json
{
  "produtos-dinamico": {
    "mappings": {
      "properties": {
        "nome": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "preco": {
          "type": "float"
        },
        "em_estoque": {
          "type": "boolean"
        },
        "tags": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "criado_em": {
          "type": "date"
        }
      }
    }
  }
}
```

**Vantagens:**

- ‚úì Prototipagem r√°pida
- ‚úì Flexibilidade imediata
- ‚úì Ideal para dados explorat√≥rios

**Desvantagens:**

- ‚úó Tipos podem n√£o ser √≥timos
- ‚úó Dificil controlar formato de datas
- ‚úó Pode causar inconsist√™ncias entre documentos

### 2.2.2 Mapping Expl√≠cito

Para aplica√ß√µes em produ√ß√£o, √© recomendado definir o mapping **explicitamente** antes de indexar dados. Isso garante consist√™ncia, performance e controle total.

**Exemplo: Criando um √≠ndice com mapping expl√≠cito**

```bash
# Requisi√ß√£o HTTP PUT
PUT http://localhost:9200/produtos-explicitamente-mapeado
Content-Type: application/json

{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  },
  "mappings": {
    "properties": {
      "id_produto": {
        "type": "keyword",
        "index": true
      },
      "nome": {
        "type": "text",
        "analyzer": "standard",
        "fields": {
          "raw": {
            "type": "keyword"
          }
        }
      },
      "descricao": {
        "type": "text",
        "analyzer": "portuguese"
      },
      "preco": {
        "type": "float"
      },
      "categoria": {
        "type": "keyword"
      },
      "estoque": {
        "type": "integer"
      },
      "ativo": {
        "type": "boolean"
      },
      "criado_em": {
        "type": "date",
        "format": "strict_date_time"
      },
      "atualizado_em": {
        "type": "date",
        "format": "strict_date_time"
      },
      "localizacao": {
        "type": "geo_point"
      }
    }
  }
}
```

**Par√¢metros importantes do mapping:**

- **type**: Tipo de dado (text, keyword, integer, date, etc.)
- **analyzer**: Analisador para processamento de texto
- **index**: Se o campo deve ser index√°vel (true/false)
- **store**: Se o valor original deve ser armazenado separadamente
- **fields**: Sub-campos adicionais (exemplo: nome.raw para valor exato)
- **format**: Formato espec√≠fico para datas

### 2.2.3 Padr√£o Multi-Campo (Multi-field)

Uma abordagem poderosa √© mapear um campo de m√∫ltiplas formas, permitindo diferentes tipos de buscas:

```json
{
  "properties": {
    "titulo": {
      "type": "text",
      "analyzer": "portuguese",
      "fields": {
        "raw": {
          "type": "keyword"
        },
        "comprimento": {
          "type": "token_count",
          "analyzer": "standard"
        }
      }
    }
  }
}
```

Isso permite:
- Busca em texto completo: `GET /_search { "query": { "match": { "titulo": "opensearch" } } }`
- Filtro exato: `GET /_search { "query": { "term": { "titulo.raw": "OpenSearch" } } }`
- Contagem de palavras: `GET /_search { "aggs": { "media_palavras": { "avg": { "field": "titulo.comprimento" } } } }`

---

### ‚ö†Ô∏è **BOX DE ALERTA: Modificar Mapping em Produ√ß√£o**

Uma vez que um √≠ndice est√° criado e cont√©m dados, **n√£o √© poss√≠vel modificar o tipo de um campo existente**. Para alterar o mapping, voc√™ deve:

1. Criar um novo √≠ndice com o mapping corrigido
2. Reindexar dados do √≠ndice antigo para o novo
3. Atualizar aliases para apontar ao novo √≠ndice
4. Remover o √≠ndice antigo

Esta √© uma opera√ß√£o cr√≠tica que deve ser planejada com cuidado em produ√ß√£o.

---

### 2.2.4 Controle Din√¢mico de Mapping: dynamic_templates, dynamic: false e dynamic: strict

O OpenSearch oferece um controle granular sobre como novos campos s√£o tratados durante a indexa√ß√£o atrav√©s da propriedade `dynamic`. Essa configura√ß√£o √© cr√≠tica para garantir qualidade de dados e evitar problemas em produ√ß√£o.

#### **Op√ß√£o 1: dynamic: true (Padr√£o)**

Permite que qualquer novo campo seja indexado automaticamente, criando o mapping dinamicamente:

```bash
PUT http://localhost:9200/usuarios-dinamico
Content-Type: application/json

{
  "mappings": {
    "dynamic": true,
    "properties": {
      "id": { "type": "keyword" },
      "nome": { "type": "text" }
    }
  }
}
```

```bash
# Indexando documento com campos extras
POST http://localhost:9200/usuarios-dinamico/_doc
Content-Type: application/json

{
  "id": "user123",
  "nome": "Jo√£o Silva",
  "email": "joao@example.com",
  "data_nascimento": "1990-05-15",
  "ativo": true
}
```

**Resultado**: Os campos `email`, `data_nascimento` e `ativo` s√£o **automaticamente adicionados** ao mapping com tipos detectados.

**Impactos:**
- ‚úÖ Flexibilidade para dados explorat√≥rios
- ‚úÖ Prototipagem r√°pida
- ‚ùå Pode criar mappings sub-√≥timos (tipos incorretos)
- ‚ùå Dif√≠cil controlar crescimento descontrolado de campos
- ‚ùå Consumo adicional de mem√≥ria e disco

---

#### **Op√ß√£o 2: dynamic: false**

Novos campos s√£o **ignorados** durante a indexa√ß√£o. O documento √© armazenado, mas os novos campos n√£o s√£o indexados nem consult√°veis:

```bash
PUT http://localhost:9200/usuarios-restritivo
Content-Type: application/json

{
  "mappings": {
    "dynamic": false,
    "properties": {
      "id": { "type": "keyword" },
      "nome": { "type": "text" },
      "email": { "type": "keyword" }
    }
  }
}
```

```bash
# Indexando documento com campo extra n√£o definido
POST http://localhost:9200/usuarios-restritivo/_doc/1
Content-Type: application/json

{
  "id": "user123",
  "nome": "Maria Santos",
  "email": "maria@example.com",
  "telefone": "(11) 99999-8888"
}
```

**Resultado**: O campo `telefone` √© **armazenado mas n√£o indexado**. Buscas pelo telefone falhar√£o, mas o dado original est√° presente no documento original (_source).

**Impactos:**
- ‚úÖ Controle total sobre schema
- ‚úÖ Evita crescimento descontrolado de campos
- ‚úÖ Melhor previsibilidade e estabilidade
- ‚úÖ Economiza mem√≥ria e espa√ßo
- ‚ùå Dados extras s√£o ignorados (n√£o consult√°veis)
- ‚ùå Menos flexibilidade

---

#### **Op√ß√£o 3: dynamic: strict**

Rejeita qualquer documento que contenha campos n√£o definidos no mapping, lan√ßando um erro:

```bash
PUT http://localhost:9200/usuarios-rigoroso
Content-Type: application/json

{
  "mappings": {
    "dynamic": "strict",
    "properties": {
      "id": { "type": "keyword" },
      "nome": { "type": "text" },
      "email": { "type": "keyword" }
    }
  }
}
```

```bash
# Tentativa de indexar documento com campo extra
POST http://localhost:9200/usuarios-rigoroso/_doc/1
Content-Type: application/json

{
  "id": "user123",
  "nome": "Pedro Costa",
  "email": "pedro@example.com",
  "telefone": "(11) 88888-7777"
}
```

**Resultado**: Erro 400 (Bad Request):

```json
{
  "error": {
    "root_cause": [
      {
        "type": "strict_dynamic_mapping_exception",
        "reason": "mapping set to strict, dynamic introduction of [telefone] within [_doc] is not allowed"
      }
    ]
  }
}
```

**Impactos:**
- ‚úÖ M√°xima integridade de dados
- ‚úÖ Detecta problemas imediatamente
- ‚úÖ For√ßa conscientiza√ß√£o sobre estrutura
- ‚úÖ Ideal para APIs bem definidas
- ‚ùå Muito r√≠gido para dados explorat√≥rios
- ‚ùå Requer predefini√ß√£o completa de campos

---

#### **Op√ß√£o 4: dynamic_templates (Padr√£o Inteligente)**

Permite criar padr√µes que aplicam tipos autom√°ticos com base em nomes ou valores de campos:

```bash
PUT http://localhost:9200/produtos-inteligente
Content-Type: application/json

{
  "mappings": {
    "dynamic": "true",
    "dynamic_templates": [
      {
        "strings_como_keyword": {
          "match_mapping_type": "string",
          "mapping": {
            "type": "keyword"
          }
        }
      },
      {
        "campos_data": {
          "match": "*_data",
          "match_mapping_type": "string",
          "mapping": {
            "type": "date",
            "format": "yyyy-MM-dd||strict_date_time"
          }
        }
      },
      {
        "campos_preco": {
          "match": "preco*",
          "match_mapping_type": "double",
          "mapping": {
            "type": "scaled_float",
            "scaling_factor": 100
          }
        }
      }
    ],
    "properties": {
      "id": { "type": "keyword" },
      "nome": { "type": "text" }
    }
  }
}
```

```bash
# Indexando documento
POST http://localhost:9200/produtos-inteligente/_doc
Content-Type: application/json

{
  "id": "prod001",
  "nome": "Notebook",
  "categoria": "eletr√¥nicos",
  "lancamento_data": "2025-01-15",
  "preco_unitario": 2500.50,
  "preco_promocional": 1999.99
}
```

**Resultado**: Os campos s√£o mapeados segundo as regras definidas:
- `categoria` ‚Üí keyword (strings como keyword)
- `lancamento_data` ‚Üí date (campo com sufixo _data)
- `preco_unitario` e `preco_promocional` ‚Üí scaled_float (campos com prefixo preco)

**Impactos:**
- ‚úÖ Flexibilidade com controle inteligente
- ‚úÖ Detecta padr√µes e aplica tipos apropriados
- ‚úÖ Reduz necessidade de mapping expl√≠cito completo
- ‚úÖ Ideal para esquemas semi-estruturados
- ‚ö†Ô∏è Requer compreens√£o das regras de correspond√™ncia

---

#### **Compara√ß√£o Pr√°tica: Impactos na Indexa√ß√£o**

```mermaid
graph TD
    A["Novo Campo Detectado<br/>na Indexa√ß√£o"] --> B{"Qual configura√ß√£o<br/>dynamic?"}

    B -->|dynamic: true| C["Campo Indexado<br/>Tipo Auto-detectado"]
    B -->|dynamic: false| D["Campo N√£o Indexado<br/>Armazenado em _source"]
    B -->|dynamic: strict| E["Erro 400<br/>Documento Rejeitado"]
    B -->|dynamic_templates| F["Padr√µes Aplicados<br/>Tipo Inteligente"]

    C --> C1["‚úÖ Flex√≠vel<br/>‚ùå Menos Previs√≠vel"]
    D --> D1["‚úÖ Controlado<br/>‚ùå Dados n√£o consult√°veis"]
    E --> E1["‚úÖ Seguro<br/>‚ùå R√≠gido demais"]
    F --> F1["‚úÖ Equilibrado<br/>‚úÖ Controlado"]

    style C fill:#fff9c4
    style D fill:#ffccbc
    style E fill:#ffccbc
    style F fill:#c8e6c9
```

---

#### **üìå BOX DE DEFINI√á√ÉO: Quando Usar Cada Op√ß√£o**

| Cen√°rio | Recomenda√ß√£o | Raz√£o |
|---------|--------------|-------|
| Desenvolvimento/Prototipagem | `dynamic: true` | Flexibilidade m√°xima |
| APIs com schema definido | `dynamic: strict` | Garantir integridade |
| Dados log/eventos vari√°veis | `dynamic_templates` | Padr√µes inteligentes |
| Dados estruturados em produ√ß√£o | `dynamic: false` | Controle + armazenamento |
| Mix: estruturado + explorat√≥rio | `dynamic_templates` | Melhor dos dois mundos |

---

## 2.3 ANALYZERS E TOKENIZA√á√ÉO

### Testando Analyzers com a API _analyze

Antes de definir analyzers em seus √≠ndices, √© essencial entender como eles processam textos. A API `POST _analyze` permite testar analyzers sem criar √≠ndices:

#### **Testando Analyzer Padr√£o (Standard)**

```bash
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "analyzer": "standard",
  "text": "O r√°pido raposa marrom pulou sobre a cerca!"
}
```

**Resposta detalhada:**

```json
{
  "tokens": [
    {
      "token": "o",
      "start_offset": 0,
      "end_offset": 1,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "r√°pido",
      "start_offset": 2,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "raposa",
      "start_offset": 9,
      "end_offset": 15,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "marrom",
      "start_offset": 16,
      "end_offset": 22,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "pulou",
      "start_offset": 23,
      "end_offset": 28,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "sobre",
      "start_offset": 29,
      "end_offset": 34,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "a",
      "start_offset": 35,
      "end_offset": 36,
      "type": "<ALPHANUM>",
      "position": 6
    },
    {
      "token": "cerca",
      "start_offset": 37,
      "end_offset": 42,
      "type": "<ALPHANUM>",
      "position": 7
    }
  ]
}
```

**Interpreta√ß√£o dos resultados:**

| Campo | Significado |
|-------|-----------|
| `token` | Palavra processada (lowercased, sem pontua√ß√£o) |
| `start_offset` | Posi√ß√£o inicial no texto original |
| `end_offset` | Posi√ß√£o final no texto original |
| `type` | Tipo de token (`<ALPHANUM>`, `<NUM>`, etc.) |
| `position` | Posi√ß√£o sequencial do token |

---

#### **Testando Portuguese Analyzer (Stopwords + Stemming)**

```bash
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "analyzer": "portuguese",
  "text": "Os usu√°rios executando opera√ß√µes de busca e indexa√ß√£o rapidamente"
}
```

**Resposta:**

```json
{
  "tokens": [
    {
      "token": "usu√°r",
      "start_offset": 4,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "execut",
      "start_offset": 13,
      "end_offset": 24,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "opera√ß",
      "start_offset": 25,
      "end_offset": 35,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "busc",
      "start_offset": 39,
      "end_offset": 45,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "index",
      "start_offset": 48,
      "end_offset": 57,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "rapid",
      "start_offset": 58,
      "end_offset": 67,
      "type": "<ALPHANUM>",
      "position": 6
    }
  ]
}
```

**Observe que:**
- ‚úÖ Stopwords removidas: "os", "de", "e"
- ‚úÖ Stemming aplicado: "usu√°rios" ‚Üí "usu√°r", "executando" ‚Üí "execut", "busca" ‚Üí "busc"
- ‚úÖ Posi√ß√µes sequenciais refletem remo√ß√£o de stopwords (pos 1, 2, 3, 4, 5, 6)

---

#### **Testando Whitespace Analyzer (Sem Processamento)**

```bash
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "analyzer": "whitespace",
  "text": "OpenSearch √© poderoso, eficiente e escal√°vel!"
}
```

**Resposta:**

```json
{
  "tokens": [
    {
      "token": "OpenSearch",
      "start_offset": 0,
      "end_offset": 10,
      "type": "word",
      "position": 0
    },
    {
      "token": "√©",
      "start_offset": 11,
      "end_offset": 12,
      "type": "word",
      "position": 1
    },
    {
      "token": "poderoso,",
      "start_offset": 13,
      "end_offset": 22,
      "type": "word",
      "position": 2
    },
    {
      "token": "eficiente",
      "start_offset": 23,
      "end_offset": 32,
      "type": "word",
      "position": 3
    },
    {
      "token": "e",
      "start_offset": 33,
      "end_offset": 34,
      "type": "word",
      "position": 4
    },
    {
      "token": "escal√°vel!",
      "start_offset": 35,
      "end_offset": 45,
      "type": "word",
      "position": 5
    }
  ]
}
```

**Observe que:**
- ‚ö†Ô∏è Pontua√ß√£o preservada: "poderoso," e "escal√°vel!" mant√™m a pontua√ß√£o
- ‚ö†Ô∏è Case preservado: "OpenSearch" mant√©m capitaliza√ß√£o
- ‚úÖ Apenas divide por espa√ßos em branco

---

#### **Compara√ß√£o: Standard vs Portuguese vs Whitespace**

Texto de entrada: *"Rapidamente buscando documentos importantes"*

```mermaid
graph TD
    A["Text: Rapidamente buscando<br/>documentos importantes"] -->|Standard| B["rapidly<br/>buscando<br/>documentos<br/>importante"]
    A -->|Portuguese| C["rapid<br/>busc<br/>document<br/>important"]
    A -->|Whitespace| D["Rapidamente<br/>buscando<br/>documentos<br/>importantes"]

    style B fill:#bbdefb
    style C fill:#c8e6c9
    style D fill:#ffccbc
```

---

#### **Testando Analyzer Customizado**

Criar um analyzer customizado e test√°-lo:

```bash
PUT http://localhost:9200/teste-custom-analyzer
Content-Type: application/json

{
  "settings": {
    "analysis": {
      "analyzer": {
        "meu_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "stop", "snowball"]
        }
      }
    }
  }
}
```

```bash
# Testando o analyzer customizado
POST http://localhost:9200/teste-custom-analyzer/_analyze
Content-Type: application/json

{
  "analyzer": "meu_analyzer",
  "text": "O OpenSearch √© excelente para buscas em texto!"
}
```

**Resposta:**

```json
{
  "tokens": [
    {
      "token": "opensearch",
      "start_offset": 2,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "excelent",
      "start_offset": 16,
      "end_offset": 25,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "busc",
      "start_offset": 30,
      "end_offset": 36,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "text",
      "start_offset": 37,
      "end_offset": 42,
      "type": "<ALPHANUM>",
      "position": 3
    }
  ]
}
```

---

### Conceito Fundamental

### Conceito Fundamental

Um **analyzer** √© um componente que processa texto para preparar campos do tipo `text` para indexa√ß√£o e busca. Ele transforma texto bruto em tokens (palavras individuais) que s√£o indexados no inverted index.

A tokeniza√ß√£o correta √© essencial para a qualidade das buscas. Por exemplo:

- Texto original: "O r√°pido raposa marrom pulou sobre a cerca"
- Tokens ap√≥s an√°lise: ["r√°pido", "raposa", "marrom", "pulou", "cerca"]

### 2.3.1 Componentes de um Analyzer

Um analyzer √© composto por tr√™s componentes:

1. **Character Filter**: Processa caracteres antes da tokeniza√ß√£o
2. **Tokenizer**: Divide o texto em tokens
3. **Token Filter**: Modifica tokens ap√≥s tokeniza√ß√£o

**Fluxo de an√°lise passo a passo:**

```mermaid
graph TD
    A["Texto Original:<br/>Hello WORLD!<br/>a√ß√£o r√°pida"] --> B["Character Filters"]
    B --> B1["Remove HTML<br/>Normaliza espa√ßos"]
    B1 --> C["Tokenizer"]
    C --> C1["Divide por<br/>espa√ßo/pontua√ß√£o"]
    C1 --> D["Token Filters"]
    D --> D1["lowercase<br/>remove stopwords<br/>stemming"]
    D1 --> E["Tokens Indexados:<br/>hello, world<br/>acao, rapid"]
    
    style A fill:#fff9c4
    style B fill:#f8bbd0
    style C fill:#bbdefb
    style D fill:#c8e6c9
    style E fill:#ffe0b2
```

### 2.3.2 Analyzers Pr√©-configurados

O OpenSearch fornece diversos analyzers prontos para uso:

**Compara√ß√£o visual de analyzers:**

```mermaid
graph TD
    A["Texto: Hello World!"] --> B["Standard"]
    A --> C["Simple"]
    A --> D["Whitespace"]
    A --> E["Keyword"]
    
    B --> B1["hello, world"]
    C --> C1["hello, world"]
    D --> D1["Hello, World!"]
    E --> E1["hello world!"]
    
    style B1 fill:#c8e6c9
    style C1 fill:#c8e6c9
    style D1 fill:#ffccbc
    style E1 fill:#fff9c4
```

**Caracter√≠sticas de cada analyzer:**

**Standard Analyzer** (padr√£o)
- Character Filter: Nenhum
- Tokenizer: standard (divide por espa√ßo e pontua√ß√£o)
- Token Filter: lowercase
- Exemplo: "Hello World!" ‚Üí ["hello", "world"]

**Simple Analyzer**
- Tokenizer: lowercase
- Divide por caracteres n√£o-alfanum√©ricos
- Exemplo: "Hello World!" ‚Üí ["hello", "world"]

**Whitespace Analyzer**
- Tokenizer: whitespace
- Divide apenas por espa√ßo em branco
- Exemplo: "Hello-World!" ‚Üí ["hello-world!"]

**Keyword Analyzer**
- N√£o divide o texto, trata como single token
- Ideal para valores que devem permanecer √≠ntegros
- Exemplo: "Hello World!" ‚Üí ["hello world!"]

**Language Analyzers**
- Espec√≠ficos por idioma (english, portuguese, spanish, etc.)
- Incluem stopwords removal e stemming
- Exemplo com "portuguese": "executando" ‚Üí ["execut"]

### 2.3.3 Criando Analyzers Customizados

Para necessidades espec√≠ficas, voc√™ pode criar analyzers personalizados:

**Exemplo: Analyzer customizado para logs de API**

```bash
PUT http://localhost:9200/logs-api
Content-Type: application/json

{
  "settings": {
    "analysis": {
      "analyzer": {
        "log_analyzer": {
          "type": "custom",
          "char_filter": ["html_strip"],
          "tokenizer": "standard",
          "filter": ["lowercase", "stop", "snowball"]
        }
      },
      "char_filter": {
        "html_strip": {
          "type": "html_strip",
          "escaped_tags": ["b", "i"]
        }
      },
      "filter": {
        "stop": {
          "type": "stop",
          "stopwords": ["_english_", "para", "de", "a"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "mensagem": {
        "type": "text",
        "analyzer": "log_analyzer"
      },
      "level": {
        "type": "keyword"
      },
      "timestamp": {
        "type": "date"
      }
    }
  }
}
```

**Exemplo: Analyzer para busca de nomes pr√≥prios (case-insensitive, sem stemming)**

```json
{
  "settings": {
    "analysis": {
      "analyzer": {
        "nome_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "nome_pessoa": {
        "type": "text",
        "analyzer": "nome_analyzer"
      }
    }
  }
}
```

### 2.3.4 Token Filters Importantes

| Filter | Fun√ß√£o | Exemplo |
|--------|--------|---------|
| lowercase | Converte para min√∫sculas | "HELLO" ‚Üí "hello" |
| stop | Remove palavras comuns | "the quick brown" ‚Üí "quick brown" |
| snowball | Stemming (raiz da palavra) | "running" ‚Üí "run" |
| synonym | Substitui por sin√¥nimos | "carro" ‚Üí "carro, autom√≥vel" |
| length | Filtra por comprimento | Mant√©m tokens com 3-20 caracteres |

---

### üí° **BOX DE DICA: Escolhendo o Analyzer Correto**

- **Buscas em texto completo**: Use language analyzers espec√≠ficos (portuguese, english)
- **Buscas facetadas/filtros**: Use keyword (sem an√°lise)
- **URLs e c√≥digos**: Use whitespace ou custom sem stemming
- **Buscas multi-idioma**: Crie m√∫ltiplos campos com analyzers diferentes

---

## 2.4 INVERTED INDEX E ESTRUTURAS INTERNAS

### O Cora√ß√£o da Busca: Inverted Index

O **inverted index** √© a estrutura de dados fundamental que permite buscas ultra-r√°pidas no OpenSearch. Diferentemente de um √≠ndice tradicional que mapeia documentos ‚Üí conte√∫do, o inverted index mapeia **termos ‚Üí documentos**.

**Visualiza√ß√£o comparativa: Forward vs. Inverted Index**

```mermaid
graph LR
    subgraph "Forward Index<br/>(Tradicional)"
        A1["Doc 1 ‚Üí termos"]
        A2["Doc 2 ‚Üí termos"]
        A3["Doc 3 ‚Üí termos"]
    end
    
    subgraph "Inverted Index<br/>(OpenSearch)"
        B1["Termo ‚Üí docs"]
        B2["Termo ‚Üí docs"]
        B3["Termo ‚Üí docs"]
    end
    
    A1 -->|Busca lenta| X["Resultado"]
    A2 -->|Busca lenta| X
    A3 -->|Busca lenta| X
    
    B1 -->|Busca r√°pida| X
    B2 -->|Busca r√°pida| X
    B3 -->|Busca r√°pida| X
    
    style A1 fill:#ffccbc
    style A2 fill:#ffccbc
    style A3 fill:#ffccbc
    style B1 fill:#c8e6c9
    style B2 fill:#c8e6c9
    style B3 fill:#c8e6c9
```

**Exemplo detalhado de inverted index:**

```
Documentos originais:
Doc 1: "OpenSearch √© um mecanismo de busca"
Doc 2: "OpenSearch √© distribu√≠do"
Doc 3: "Busca r√°pida com OpenSearch"

Inverted Index resultante:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Termo       ‚îÇ Documentos       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ OpenSearch  ‚îÇ [Doc 1, Doc 2, Doc 3] ‚îÇ
‚îÇ √©           ‚îÇ [Doc 1, Doc 2]   ‚îÇ
‚îÇ um          ‚îÇ [Doc 1]          ‚îÇ
‚îÇ mecanismo   ‚îÇ [Doc 1]          ‚îÇ
‚îÇ de          ‚îÇ [Doc 1, Doc 3]   ‚îÇ
‚îÇ busca       ‚îÇ [Doc 1, Doc 3]   ‚îÇ
‚îÇ distribu√≠do ‚îÇ [Doc 2]          ‚îÇ
‚îÇ r√°pida      ‚îÇ [Doc 3]          ‚îÇ
‚îÇ com         ‚îÇ [Doc 3]          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Quando voc√™ busca por "OpenSearch busca", o sistema consulta o √≠ndice invertido:
- Encontra "OpenSearch" ‚Üí [Doc 1, Doc 2, Doc 3]
- Encontra "busca" ‚Üí [Doc 1, Doc 3]
- Retorna intersec√ß√£o: [Doc 1, Doc 3]

**Vantagem**: Em vez de ler todos os documentos sequencialmente, o sistema encontra diretamente quais documentos cont√™m os termos procurados.

### 2.4.1 Estrutura Interna de um Inverted Index

Para cada termo, o inverted index armazena mais que apenas a lista de documentos. Ele mant√©m informa√ß√µes detalhadas para scoring (c√°lculo de relev√¢ncia):

**Componentes de uma posting list:**

```mermaid
graph TD
    A["Termo: OpenSearch"] --> B["Metadados do Termo"]
    A --> C["Posting List"]
    
    B --> B1["Document Frequency: 3"]
    B --> B2["Total occurrences: 3"]
    
    C --> C1["Doc 1"]
    C --> C2["Doc 2"]
    C --> C3["Doc 3"]
    
    C1 --> C1A["TF: 1"]
    C1 --> C1B["Posi√ß√£o: 0"]
    C1 --> C1C["Offsets: 0-10"]
    
    C2 --> C2A["TF: 1"]
    C2 --> C2B["Posi√ß√£o: 0"]
    C2 --> C2C["Offsets: 0-10"]
    
    C3 --> C3A["TF: 1"]
    C3 --> C3B["Posi√ß√£o: 2"]
    C3 --> C3C["Offsets: 16-26"]
    
    style B fill:#bbdefb
    style C fill:#c8e6c9
```

Estrutura detalhada em formato textual:

```
Termo: "OpenSearch"
‚îú‚îÄ‚îÄ Document Frequency: 3 (aparece em 3 documentos)
‚îú‚îÄ‚îÄ Posting List:
‚îÇ   ‚îú‚îÄ‚îÄ Doc 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Term Frequency: 1 (aparece 1 vez)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Posi√ß√£o: 0 (primeira palavra)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Offsets: 0-10 (bytes no documento)
‚îÇ   ‚îú‚îÄ‚îÄ Doc 2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Term Frequency: 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Posi√ß√£o: 0
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Offsets: 0-10
‚îÇ   ‚îî‚îÄ‚îÄ Doc 3
‚îÇ       ‚îú‚îÄ‚îÄ Term Frequency: 1
‚îÇ       ‚îú‚îÄ‚îÄ Posi√ß√£o: 2
‚îÇ       ‚îî‚îÄ‚îÄ Offsets: 16-26
```

### 2.4.2 BM25: Algoritmo de Scoring de Relev√¢ncia

O OpenSearch utiliza por padr√£o o **BM25** (Best Matching 25) como algoritmo de scoring para calcular a relev√¢ncia de cada documento em uma busca. O BM25 √© uma evolu√ß√£o sofisticada do TF-IDF que leva em conta fatores adicionais para resultados mais relevantes.

**Por que BM25 em vez de TF-IDF?**

O BM25 melhora o TF-IDF com:
- **Satura√ß√£o de frequ√™ncia**: N√£o assume que frequ√™ncia infinita sempre = maior relev√¢ncia
- **Normaliza√ß√£o por comprimento**: Documentos mais curtos n√£o s√£o penalizados automaticamente
- **Parametriza√ß√£o**: Permite ajuste fino via par√¢metros k1 e b
- **IDF melhorado**: C√°lculo mais robusto da raridade do termo

**Componentes do BM25:**

```mermaid
graph LR
    A["BM25<br/>Okapi"] --> B["IDF<br/>Raridade"]
    A --> C["TF<br/>Frequ√™ncia"]
    A --> D["Field Length<br/>Normaliza√ß√£o"]

    B --> B1["Penaliza termos<br/>muito comuns"]
    B --> B2["Premia termos<br/>raros"]

    C --> C1["Satura√ß√£o:<br/>frequ√™ncia 5 vs 10<br/>n√£o √© 2x melhor"]
    C --> C2["Ajust√°vel com<br/>par√¢metro k1"]

    D --> D1["Compensa por<br/>tamanho do doc"]
    D --> D2["Ajust√°vel com<br/>par√¢metro b"]

    style B1 fill:#c8e6c9
    style B2 fill:#c8e6c9
    style C1 fill:#bbdefb
    style C2 fill:#bbdefb
    style D1 fill:#fff9c4
    style D2 fill:#fff9c4
```

**F√≥rmula de scoring BM25:**

```
Score(D, Q) = Œ£ IDF(qi) √ó ((k1 + 1) √ó TF(qi, D)) / (TF(qi, D) + k1 √ó (1 - b + b √ó (|D| / avgdl)))

Onde:
  D = documento
  Q = query (termos pesquisados)
  IDF(qi) = log((N - n(qi) + 0.5) / (n(qi) + 0.5))
  N = total de documentos
  n(qi) = documentos contendo o termo qi
  TF(qi, D) = frequ√™ncia do termo no documento
  |D| = comprimento do documento (em termos)
  avgdl = comprimento m√©dio dos documentos
  k1 = par√¢metro de satura√ß√£o (padr√£o: 1.2)
  b = par√¢metro de normaliza√ß√£o (padr√£o: 0.75)
```

**Componentes explicados:**

**IDF (Inverse Document Frequency):**
```
IDF(termo) = log((total_docs - docs_com_termo + 0.5) / (docs_com_termo + 0.5))
```
- Maior IDF = termo mais raro = mais importante
- 0.5 adicionado para evitar divis√£o por zero

**TF (Term Frequency com satura√ß√£o):**
```
TF saturado = ((k1 + 1) √ó freq) / (freq + k1)
```
- Com k1=1.2, a frequ√™ncia √© saturada
- Frequ√™ncia 1 contribui ~55% do m√°ximo
- Frequ√™ncia 2 contribui ~73% do m√°ximo
- Frequ√™ncia infinita contribui 100%

**Field Length Normalization:**
```
normaliza√ß√£o = (1 - b + b √ó (comprimento_doc / comprimento_m√©dio))
```
- Com b=0.75, documentos menores s√£o ligeiramente favorecidos
- b=0 desativa normaliza√ß√£o completamente
- b=1 penaliza fortemente documentos grandes

---

**Exemplo pr√°tico de c√°lculo BM25:**

Cen√°rio: 100 documentos no √≠ndice, 40 cont√™m "OpenSearch", 5 cont√™m "distribu√≠do"

```
Busca: "OpenSearch distribu√≠do"

Comprimentos:
- Documento 1: 150 termos
- Documento 2: 100 termos
- Documento 3: 120 termos
- Comprimento m√©dio (avgdl): 115 termos

C√°lculo de IDF:
- IDF("OpenSearch") = log((100 - 40 + 0.5) / (40 + 0.5)) = log(1.48) = 0.392
- IDF("distribu√≠do") = log((100 - 5 + 0.5) / (5 + 0.5)) = log(19.1) = 2.95

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Documento 1: "OpenSearch √© um mecanismo de busca distribu√≠do..." (150 termos)
‚îú‚îÄ‚îÄ Cont√©m "OpenSearch": 2 vezes
‚îú‚îÄ‚îÄ Cont√©m "distribu√≠do": 1 vez
‚îú‚îÄ‚îÄ
‚îú‚îÄ‚îÄ C√°lculo TF("OpenSearch"):
‚îÇ   TF saturado = (2.2 √ó 2) / (2 + 1.2) = 4.4 / 3.2 = 1.375
‚îÇ
‚îú‚îÄ‚îÄ Normaliza√ß√£o de comprimento:
‚îÇ   norm = (1 - 0.75 + 0.75 √ó (150 / 115)) = 0.25 + 0.978 = 1.228
‚îÇ
‚îú‚îÄ‚îÄ Score para "OpenSearch":
‚îÇ   0.392 √ó 1.375 / 1.228 = 0.440
‚îÇ
‚îú‚îÄ‚îÄ Score para "distribu√≠do":
‚îÇ   TF saturado = (2.2 √ó 1) / (1 + 1.2) = 2.2 / 2.2 = 1.0
‚îÇ   2.95 √ó 1.0 / 1.228 = 2.402
‚îÇ
‚îî‚îÄ‚îÄ SCORE TOTAL: 0.440 + 2.402 = 2.842 ‚úì BOM

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Documento 2: "OpenSearch √© distribu√≠do e r√°pido" (100 termos)
‚îú‚îÄ‚îÄ Cont√©m "OpenSearch": 1 vez
‚îú‚îÄ‚îÄ Cont√©m "distribu√≠do": 1 vez
‚îú‚îÄ‚îÄ
‚îú‚îÄ‚îÄ C√°lculo TF("OpenSearch"):
‚îÇ   TF saturado = (2.2 √ó 1) / (1 + 1.2) = 2.2 / 2.2 = 1.0
‚îÇ
‚îú‚îÄ‚îÄ Normaliza√ß√£o de comprimento:
‚îÇ   norm = (1 - 0.75 + 0.75 √ó (100 / 115)) = 0.25 + 0.652 = 0.902
‚îÇ
‚îú‚îÄ‚îÄ Score para "OpenSearch":
‚îÇ   0.392 √ó 1.0 / 0.902 = 0.435
‚îÇ
‚îú‚îÄ‚îÄ Score para "distribu√≠do":
‚îÇ   2.95 √ó 1.0 / 0.902 = 3.270
‚îÇ
‚îî‚îÄ‚îÄ SCORE TOTAL: 0.435 + 3.270 = 3.705 ‚úì MELHOR (doc mais conciso)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Documento 3: "Busca r√°pida com OpenSearch" (50 termos)
‚îú‚îÄ‚îÄ Cont√©m "OpenSearch": 1 vez
‚îú‚îÄ‚îÄ N√£o cont√©m "distribu√≠do"
‚îú‚îÄ‚îÄ
‚îú‚îÄ‚îÄ C√°lculo TF("OpenSearch"):
‚îÇ   TF saturado = (2.2 √ó 1) / (1 + 1.2) = 1.0
‚îÇ
‚îú‚îÄ‚îÄ Normaliza√ß√£o de comprimento:
‚îÇ   norm = (1 - 0.75 + 0.75 √ó (50 / 115)) = 0.25 + 0.326 = 0.576
‚îÇ
‚îú‚îÄ‚îÄ Score para "OpenSearch":
‚îÇ   0.392 √ó 1.0 / 0.576 = 0.680
‚îÇ
‚îú‚îÄ‚îÄ Score para "distribu√≠do":
‚îÇ   0 (n√£o cont√©m)
‚îÇ
‚îî‚îÄ‚îÄ SCORE TOTAL: 0.680 + 0 = 0.680 (n√£o corresponde bem)
```

**Visualiza√ß√£o comparativa de scores:**

```mermaid
bar
    title Scores BM25 para "OpenSearch distribu√≠do"
    x-axis [Doc 1, Doc 2, Doc 3]
    y-axis "Score" 0 --> 4.0
    bar [2.842, 3.705, 0.680]
```

**Resultado**: Documento 2 (3.705) aparece primeiro, pois √© conciso e cont√©m ambos os termos. Documento 1 (2.842) tamb√©m √© relevante apesar de maior, por conter "distribu√≠do" 1 vez. Documento 3 (0.680) √© menos relevante por n√£o conter "distribu√≠do".

---

#### **Ajustando BM25 em seu √≠ndice:**

Por padr√£o, o OpenSearch usa k1=1.2 e b=0.75, o que funciona bem para a maioria dos casos. Voc√™ pode customizar:

```bash
PUT http://localhost:9200/produtos/_mapping
Content-Type: application/json

{
  "properties": {
    "descricao": {
      "type": "text",
      "analyzer": "portuguese",
      "similarity": "custom_bm25"
    }
  }
}
```

Com defini√ß√£o customizada no √≠ndice:

```bash
PUT http://localhost:9200/produtos
Content-Type: application/json

{
  "settings": {
    "similarity": {
      "custom_bm25": {
        "type": "BM25",
        "k1": 1.5,          # ‚Üë Favorece frequ√™ncia (1.5 > 1.2)
        "b": 0.5            # ‚Üì Menos penaliza√ß√£o por comprimento
      }
    }
  },
  "mappings": {
    "properties": {
      "titulo": {
        "type": "text",
        "similarity": "custom_bm25"
      }
    }
  }
}
```

**Ajustes pr√°ticos:**
- **k1 maior (1.5-2.0)**: Use quando frequ√™ncia do termo √© muito indicativa de relev√¢ncia
- **k1 menor (0.8-1.0)**: Use quando quer reduzir impacto da frequ√™ncia
- **b maior (0.9)**: Use para corpus com documentos de tamanho muito vari√°vel
- **b menor (0.2)**: Use para corpus com documentos de tamanho consistente

### 2.4.3 Shards e Replicas: Distribui√ß√£o

Um √≠ndice √© dividido em **shards** (fragmentos) para distribui√ß√£o horizontal:

**Arquitetura de shards e r√©plicas:**

```mermaid
graph TD
    A["√çndice: produtos<br/>3 Shards + Replica√ß√£o"] --> B["Cluster de 6 N√≥s"]
    
    B --> N1["N√≥ 1"]
    B --> N2["N√≥ 2"]
    B --> N3["N√≥ 3"]
    B --> N4["N√≥ 4"]
    B --> N5["N√≥ 5"]
    B --> N6["N√≥ 6"]
    
    N1 --> S1["Shard 0<br/>PRIMARY<br/>Docs 0,3,6,9..."]
    N2 --> S1R["Shard 0<br/>REPLICA<br/>Docs 0,3,6,9..."]
    
    N3 --> S2["Shard 1<br/>PRIMARY<br/>Docs 1,4,7,10..."]
    N4 --> S2R["Shard 1<br/>REPLICA<br/>Docs 1,4,7,10..."]
    
    N5 --> S3["Shard 2<br/>PRIMARY<br/>Docs 2,5,8,11..."]
    N6 --> S3R["Shard 2<br/>REPLICA<br/>Docs 2,5,8,11..."]
    
    style S1 fill:#81d4fa
    style S2 fill:#81d4fa
    style S3 fill:#81d4fa
    style S1R fill:#ffccbc
    style S2R fill:#ffccbc
    style S3R fill:#ffccbc
```

**Estrutura visual de um shard:**

```
Shard 0 (Primary) em N√≥ A
‚îú‚îÄ‚îÄ Inverted Index (termos ‚Üí documentos)
‚îú‚îÄ‚îÄ Documentos 0, 3, 6, 9, ...
‚îî‚îÄ‚îÄ Metadados do shard
    ‚îú‚îÄ‚îÄ Tamanho
    ‚îú‚îÄ‚îÄ Data de cria√ß√£o
    ‚îî‚îÄ‚îÄ Status

    ‚Üì Replicado para ‚Üì
    
Shard 0 (Replica) em N√≥ B
‚îú‚îÄ‚îÄ C√≥pia id√™ntica do Primary
‚îú‚îÄ‚îÄ Pode servir buscas
‚îî‚îÄ‚îÄ Atualizado automaticamente
```

**Benef√≠cios da arquitetura distribu√≠da:**

```mermaid
graph LR
    A["Shards + Replicas"] --> B["Paralelismo"]
    A --> C["Escalabilidade"]
    A --> D["Resili√™ncia"]
    
    B --> B1["M√∫ltiplos shards processam<br/>queries simultaneamente"]
    C --> C1["Novos n√≥s aumentam<br/>capacidade"]
    D --> D1["Replicas garantem<br/>disponibilidade"]
    
    style B1 fill:#c8e6c9
    style C1 fill:#c8e6c9
    style D1 fill:#c8e6c9
```

---

## 2.5 OPERA√á√ïES CRUD VIA API REST

**Ciclo de vida de um documento:**

```mermaid
stateDiagram-v2
    [*] --> CREATE: PUT/POST
    CREATE --> Indexado
    Indexado --> READ: GET
    Indexado --> UPDATE: POST _update
    UPDATE --> Indexado: Vers√£o incrementa
    Indexado --> DELETE: DELETE
    DELETE --> [*]
    
    Indexado --> Busca: Dispon√≠vel em buscas
    Busca --> Indexado
```

### 2.5.1 CREATE: Criando Documentos

**Opera√ß√£o Create**: Adiciona novo documento ao √≠ndice. O OpenSearch retorna erro se o documento j√° existe.

**Sintaxe:**
```
PUT /<index>/_doc/<_id>
POST /<index>/_doc
```

**Fluxo de cria√ß√£o de documento:**

```mermaid
graph TD
    A["Requisi√ß√£o CREATE"] --> B{ID Fornecido?}
    B -->|Sim| C["PUT com ID espec√≠fico"]
    B -->|N√£o| D["POST com ID auto-gerado"]
    
    C --> E["Verifica se doc<br/>j√° existe"]
    D --> E
    
    E --> F{Doc existe?}
    F -->|N√£o| G["Cria novo documento<br/>Version = 1"]
    F -->|Sim| H["Retorna erro<br/>version_conflict"]
    
    G --> I["Documento<br/>indexado"]
    H --> J["Opera√ß√£o falha"]
    
    I --> K["Status 201 Created"]
    J --> K
    
    style G fill:#c8e6c9
    style I fill:#c8e6c9
    style H fill:#ffccbc
    style J fill:#ffccbc
```

**Exemplo 1: Criar documento com ID especificado**

```bash
PUT http://localhost:9200/usuarios/_doc/user-001
Content-Type: application/json

{
  "nome": "Jo√£o Silva",
  "email": "joao@example.com",
  "idade": 28,
  "ativo": true,
  "criado_em": "2025-01-15T10:30:00Z"
}
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_type": "_doc",
  "_id": "user-001",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
```

**Exemplo 2: Criar documento com ID auto-gerado**

```bash
POST http://localhost:9200/usuarios/_doc
Content-Type: application/json

{
  "nome": "Maria Santos",
  "email": "maria@example.com",
  "idade": 32,
  "ativo": true,
  "criado_em": "2025-01-15T11:45:00Z"
}
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_id": "aBc123DeF456",
  "_version": 1,
  "result": "created"
}
```

**Exemplo 3: Criar documento com opera√ß√£o de √≠ndice (upsert)**

```bash
PUT http://localhost:9200/produtos/_doc/prod-laptop-001?op_type=create
Content-Type: application/json

{
  "nome": "Notebook Dell XPS 13",
  "preco": 4500.00,
  "categoria": "Eletr√¥nicos",
  "em_estoque": true
}
```

Se o documento j√° existir, retorna erro:
```json
{
  "error": {
    "type": "version_conflict_engine_exception",
    "reason": "[prod-laptop-001]: version conflict"
  }
}
```

---

### 2.5.2 READ: Recuperando Documentos

**Opera√ß√£o Read**: Recupera documento existente por ID.

**Sintaxe:**
```
GET /<index>/_doc/<_id>
```

**Exemplo 1: Recuperar documento espec√≠fico**

```bash
GET http://localhost:9200/usuarios/_doc/user-001
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_type": "_doc",
  "_id": "user-001",
  "_version": 1,
  "found": true,
  "_source": {
    "nome": "Jo√£o Silva",
    "email": "joao@example.com",
    "idade": 28,
    "ativo": true,
    "criado_em": "2025-01-15T10:30:00Z"
  }
}
```

**Exemplo 2: Recuperar apenas campos espec√≠ficos (partial read)**

```bash
GET http://localhost:9200/usuarios/_doc/user-001?_source=nome,email
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_id": "user-001",
  "found": true,
  "_source": {
    "nome": "Jo√£o Silva",
    "email": "joao@example.com"
  }
}
```

**Exemplo 3: Verificar exist√™ncia do documento (apenas header)**

```bash
HEAD http://localhost:9200/usuarios/_doc/user-001
```

Retorna status 200 se existe, 404 se n√£o existe.

**Exemplo 4: Recuperar m√∫ltiplos documentos (mget)**

```bash
GET http://localhost:9200/_mget
Content-Type: application/json

{
  "docs": [
    {
      "_index": "usuarios",
      "_id": "user-001"
    },
    {
      "_index": "usuarios",
      "_id": "user-002"
    },
    {
      "_index": "produtos",
      "_id": "prod-laptop-001"
    }
  ]
}
```

**Resposta:**
```json
{
  "docs": [
    {
      "_index": "usuarios",
      "_id": "user-001",
      "found": true,
      "_source": { ... }
    },
    {
      "_index": "usuarios",
      "_id": "user-002",
      "found": false
    },
    {
      "_index": "produtos",
      "_id": "prod-laptop-001",
      "found": true,
      "_source": { ... }
    }
  ]
}
```

---

### 2.5.3 UPDATE: Modificando Documentos

**Opera√ß√£o Update**: Modifica um documento existente. OpenSearch atualiza apenas os campos especificados.

**Sintaxe:**
```
POST /<index>/_update/<_id>
PUT /<index>/_doc/<_id> (substitui completamente)
```

**Compara√ß√£o entre UPDATE parcial vs. substitui√ß√£o completa:**

```mermaid
graph TD
    A["Documento Original<br/>v1"] --> B["Documento Original<br/>nome: Jo√£o<br/>email: joao@ex.com<br/>idade: 28<br/>ativo: true"]
    
    C["POST _update<br/>Parcial"] --> D["Apenas campos<br/>na requisi√ß√£o s√£o<br/>modificados"]
    D --> E["Resultado v2<br/>nome: Jo√£o<br/>email: joao@ex.com<br/>idade: 29<br/>ativo: true"]
    
    F["PUT _doc<br/>Substitui√ß√£o"] --> G["Documento completo<br/>substitui o antigo"]
    G --> H["Resultado v2<br/>novo_campo1: xxx<br/>novo_campo2: yyy<br/>(campos antigos perdidos)"]
    
    style B fill:#bbdefb
    style E fill:#c8e6c9
    style H fill:#ffccbc
```

**Fluxo de atualiza√ß√£o:**

```mermaid
graph TD
    A["Requisi√ß√£o UPDATE"] --> B{Tipo de update?}
    
    B -->|Parcial| C["POST _update"]
    B -->|Completo| D["PUT _doc"]
    
    C --> C1["L√™ documento<br/>atual"]
    C1 --> C2["Mescla campos<br/>novos"]
    C2 --> C3["Mant√©m campos<br/>n√£o informados"]
    C3 --> C4["Version incrementa"]
    
    D --> D1["Substitui<br/>completamente"]
    D1 --> D2["Campos n√£o<br/>informados<br/>s√£o perdidos"]
    D2 --> D3["Version incrementa"]
    
    C4 --> E["Documento<br/>atualizado"]
    D3 --> E
    
    style C3 fill:#c8e6c9
    style D2 fill:#ffccbc
```

**Exemplo 1: Update parcial (apenas campos alterados)**

```bash
POST http://localhost:9200/usuarios/_update/user-001
Content-Type: application/json

{
  "doc": {
    "idade": 29,
    "atualizado_em": "2025-01-16T14:20:00Z"
  }
}
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_id": "user-001",
  "_version": 2,
  "result": "updated",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  }
}
```

O documento agora cont√©m: nome, email, idade (29), ativo, criado_em, atualizado_em.

**Exemplo 2: Update com script**

```bash
POST http://localhost:9200/produtos/_update/prod-laptop-001
Content-Type: application/json

{
  "script": {
    "source": "ctx._source.estoque -= params.quantidade",
    "params": {
      "quantidade": 5
    }
  }
}
```

Este script reduz o estoque em 5 unidades. Pode ser executado atomicamente.

**Exemplo 3: Update com upsert (atualizar ou criar)**

```bash
POST http://localhost:9200/usuarios/_update/user-999
Content-Type: application/json

{
  "doc": {
    "nome": "Pedro Costa",
    "email": "pedro@example.com",
    "idade": 35,
    "ativo": true
  },
  "doc_as_upsert": true
}
```

Se user-999 n√£o existe, ser√° criado. Se existe, ser√° atualizado.

**Exemplo 4: Substitui√ß√£o completa (PUT com ID)**

```bash
PUT http://localhost:9200/usuarios/_doc/user-001
Content-Type: application/json

{
  "nome": "Jo√£o Silva Atualizado",
  "email": "joao.novo@example.com",
  "idade": 29,
  "ativo": true,
  "criado_em": "2025-01-15T10:30:00Z",
  "atualizado_em": "2025-01-16T14:20:00Z"
}
```

Substitui completamente o documento anterior. Vers√£o incrementa para 2.

---

### 2.5.4 DELETE: Removendo Documentos

**Opera√ß√£o Delete**: Remove um documento do √≠ndice.

**Sintaxe:**
```
DELETE /<index>/_doc/<_id>
```

**Estados e fluxo de dele√ß√£o:**

```mermaid
graph TD
    A["Requisi√ß√£o DELETE"] --> B["Procura documento<br/>por ID"]
    
    B --> C{Documento<br/>existe?}
    
    C -->|Sim| D["Remove documento<br/>do √≠ndice"]
    C -->|N√£o| E["Retorna<br/>not_found"]
    
    D --> F["Marca como<br/>deletado"]
    F --> G["Version incrementa"]
    G --> H["Espa√ßo pode ser<br/>reclamado<br/>em Merge"]
    
    H --> I["Status 200 OK<br/>result: deleted"]
    E --> J["Status 200 OK<br/>result: not_found"]
    
    style D fill:#c8e6c9
    style I fill:#c8e6c9
    style E fill:#fff9c4
    style J fill:#fff9c4
```

**Ciclo de vida p√≥s-dele√ß√£o:**

```mermaid
sequenceDiagram
    participant Client as Cliente
    participant OS as OpenSearch
    participant Index as √çndice
    
    Client->>OS: DELETE /usuarios/_doc/user-001
    OS->>Index: Procura documento
    Index-->>OS: Encontrado (version: 5)
    OS->>Index: Marca como deletado<br/>Nova vers√£o: 6
    Index->>Index: Inverted index<br/>atualizado
    OS-->>Client: Status 200<br/>result: deleted
    
    Note over Index: Documento f√≠sicamente<br/>ainda pode estar<br/>em segmentos
    Note over Index: Ser√° reclamado<br/>em opera√ß√µes<br/>de merge
```

**Exemplo 1: Deletar documento espec√≠fico**

```bash
DELETE http://localhost:9200/usuarios/_doc/user-999
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_id": "user-999",
  "_version": 1,
  "result": "deleted",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  }
}
```

**Exemplo 2: Tentativa de deletar documento inexistente**

```bash
DELETE http://localhost:9200/usuarios/_doc/nao-existe
```

**Resposta:**
```json
{
  "_index": "usuarios",
  "_id": "nao-existe",
  "_version": 1,
  "result": "not_found"
}
```

**Exemplo 3: Deletar m√∫ltiplos documentos por query (bulk delete)**

```bash
POST http://localhost:9200/_bulk
Content-Type: application/json

{"delete":{"_index":"usuarios","_id":"user-001"}}
{"delete":{"_index":"usuarios","_id":"user-002"}}
{"delete":{"_index":"produtos","_id":"prod-laptop-001"}}
```

**Resposta:**
```json
{
  "took": 45,
  "errors": false,
  "items": [
    {
      "delete": {
        "_index": "usuarios",
        "_id": "user-001",
        "_version": 3,
        "result": "deleted"
      }
    },
    {
      "delete": {
        "_index": "usuarios",
        "_id": "user-002",
        "result": "not_found"
      }
    },
    {
      "delete": {
        "_index": "produtos",
        "_id": "prod-laptop-001",
        "result": "deleted"
      }
    }
  ]
}
```

---

### üîê **BOX DE ALERTA: Considerar Soft Delete em Produ√ß√£o**

Deletar documentos permanentemente pode ser irrevers√≠vel. Em muitos cen√°rios de produ√ß√£o, √© prefer√≠vel usar **soft delete**:

```bash
POST /usuarios/_update/user-001
{
  "doc": {
    "deletado": true,
    "data_deletacao": "2025-01-16T15:00:00Z"
  }
}
```

Depois filtrar nas queries:
```bash
GET /usuarios/_search
{
  "query": {
    "term": {
      "deletado": false
    }
  }
}
```

---

## 2.6 OPERA√á√ïES AVAN√áADAS COM DOCUMENTOS

### 2.6.1 Bulk Operations

Para inserir, atualizar ou deletar m√∫ltiplos documentos eficientemente, use a API Bulk:

**Fluxo de processamento de bulk operations:**

```mermaid
graph TD
    A["Requisi√ß√£o BULK<br/>4 opera√ß√µes"] --> B["OpenSearch processa<br/>sequencialmente"]
    
    B --> C["1. Index user-101<br/>‚úì Status 201"]
    B --> D["2. Index user-102<br/>‚úì Status 201"]
    B --> E["3. Update user-001<br/>‚úì Status 200"]
    B --> F["4. Delete user-999<br/>‚úì Status 200"]
    
    C --> G["Resposta consolidada<br/>took: 120ms<br/>errors: false"]
    D --> G
    E --> G
    F --> G
    
    G --> H["Array com status<br/>de cada opera√ß√£o"]
    
    style C fill:#c8e6c9
    style D fill:#c8e6c9
    style E fill:#bbdefb
    style F fill:#ffccbc
    style G fill:#fff9c4
    style H fill:#fff9c4
```

**Compara√ß√£o: Single vs. Bulk Operations:**

```mermaid
graph LR
    subgraph "3 Single Requests"
        A1["PUT /usuarios/_doc/user-101"]
        A2["PUT /usuarios/_doc/user-102"]
        A3["DELETE /usuarios/_doc/user-999"]
        A1 --> B1["HTTP Round Trip 1"]
        A2 --> B2["HTTP Round Trip 2"]
        A3 --> B3["HTTP Round Trip 3"]
        B1 --> C["Total Lat√™ncia:<br/>3x lat√™ncia de rede"]
    end
    
    subgraph "1 Bulk Request"
        D["POST /_bulk<br/>3 opera√ß√µes"]
        D --> E["HTTP Round Trip 1"]
        E --> F["Total Lat√™ncia:<br/>1x lat√™ncia de rede<br/>+ processamento"]
    end
    
    C -->|Mais lento| G["~300ms"]
    F -->|Mais r√°pido| H["~100ms"]
    
    style C fill:#ffccbc
    style F fill:#c8e6c9
```

```bash
POST http://localhost:9200/_bulk
Content-Type: application/json

{"index":{"_index":"usuarios","_id":"user-101"}}
{"nome":"Alice","email":"alice@example.com","idade":25,"ativo":true}
{"index":{"_index":"usuarios","_id":"user-102"}}
{"nome":"Bob","email":"bob@example.com","idade":31,"ativo":true}
{"update":{"_index":"usuarios","_id":"user-001"}}
{"doc":{"idade":30}}
{"delete":{"_index":"usuarios","_id":"user-999"}}
```

**Resposta:**
```json
{
  "took": 120,
  "errors": false,
  "items": [
    {
      "index": {
        "_index": "usuarios",
        "_id": "user-101",
        "_version": 1,
        "result": "created"
      }
    },
    {
      "index": {
        "_index": "usuarios",
        "_id": "user-102",
        "_version": 1,
        "result": "created"
      }
    },
    {
      "update": {
        "_index": "usuarios",
        "_id": "user-001",
        "_version": 2,
        "result": "updated"
      }
    },
    {
      "delete": {
        "_index": "usuarios",
        "_id": "user-999",
        "result": "deleted"
      }
    }
  ]
}
```

**Vantagens:**
- ‚úì Uma √∫nica requisi√ß√£o HTTP para m√∫ltiplas opera√ß√µes
- ‚úì Reduz lat√™ncia de rede significativamente
- ‚úì OpenSearch processa em paralelo nos shards
- ‚úì Ideal para grandes volumes de dados

---

### 2.6.2 Versionamento de Documentos

O OpenSearch mant√©m automaticamente a vers√£o de cada documento. Isso √© √∫til para controle de concorr√™ncia:

**Hist√≥rico de vers√µes durante opera√ß√µes:**

```mermaid
graph LR
    A["Doc criado<br/>v1"] --> B["Primeiro update<br/>v2"]
    B --> C["Segundo update<br/>v3"]
    C --> D["Delete<br/>v4"]
    D --> E["Recreado<br/>v5"]
    
    style A fill:#c8e6c9
    style B fill:#bbdefb
    style C fill:#bbdefb
    style D fill:#ffccbc
    style E fill:#c8e6c9
```

**Controle de concorr√™ncia com versionamento:**

```mermaid
sequenceDiagram
    participant Client1 as Cliente 1
    participant Client2 as Cliente 2
    participant OS as OpenSearch
    
    OS->>Client1: GET user-001<br/>v5
    OS->>Client2: GET user-001<br/>v5
    
    Client1->>OS: PUT user-001?if_seq_no=5<br/>Novos dados
    OS->>OS: Valida vers√£o OK
    OS-->>Client1: Status 200<br/>v6 criada
    
    Client2->>OS: PUT user-001?if_seq_no=5<br/>Novos dados diferentes
    OS->>OS: Verifica: seq_no agora √© 6<br/>Conflito!
    OS-->>Client2: Status 409<br/>version_conflict_engine_exception
    
    Note over Client2: Cliente 2 precisa<br/>recarregar e<br/>tentar novamente
```

```bash
PUT http://localhost:9200/usuarios/_doc/user-001?if_seq_no=5&if_primary_term=1
Content-Type: application/json

{
  "nome": "Jo√£o Silva",
  "email": "joao@example.com",
  "idade": 30
}
```

Se a vers√£o n√£o corresponder, retorna erro de conflito:
```json
{
  "error": {
    "type": "version_conflict_engine_exception",
    "reason": "[user-001]: version conflict"
  }
}
```

Isso previne race conditions quando m√∫ltiplos clientes atualizam o mesmo documento.

---

## 2.7 EXERC√çCIOS PR√ÅTICOS DE FIXA√á√ÉO

### Exerc√≠cio 2.1: Criando um √çndice com Mapping Expl√≠cito

**Objetivo**: Criar um √≠ndice para gerenciar artigos de blog com tipos de dados apropriados.

**Tarefa:**
1. Crie um √≠ndice chamado `blog-posts` com mapping expl√≠cito
2. Defina os seguintes campos:
   - `titulo` (text com analyzer portuguese)
   - `conteudo` (text com analyzer portuguese)
   - `autor` (keyword)
   - `data_publicacao` (date)
   - `categoria` (keyword)
   - `tags` (array de keywords)
   - `visualizacoes` (integer)
   - `curtidas` (integer)
   - `ativo` (boolean)

3. Teste inserindo um documento de exemplo

**Resposta esperada:**
```bash
PUT http://localhost:9200/blog-posts
Content-Type: application/json

{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  },
  "mappings": {
    "properties": {
      "titulo": {
        "type": "text",
        "analyzer": "portuguese"
      },
      "conteudo": {
        "type": "text",
        "analyzer": "portuguese"
      },
      "autor": {
        "type": "keyword"
      },
      "data_publicacao": {
        "type": "date"
      },
      "categoria": {
        "type": "keyword"
      },
      "tags": {
        "type": "keyword"
      },
      "visualizacoes": {
        "type": "integer"
      },
      "curtidas": {
        "type": "integer"
      },
      "ativo": {
        "type": "boolean"
      }
    }
  }
}
```

### Exerc√≠cio 2.2: Opera√ß√µes CRUD Completas

**Objetivo**: Executar todas as opera√ß√µes CRUD em um √≠ndice.

**Tarefa:**
1. Crie um documento no √≠ndice `blog-posts` com ID `post-001`
2. Recupere o documento
3. Atualize apenas o campo `visualizacoes` para 150
4. Recupere novamente para confirmar
5. Delete o documento
6. Tente recuperar (deve retornar not found)

**Passo a passo:**

```bash
# CREATE
POST http://localhost:9200/blog-posts/_doc/post-001
Content-Type: application/json

{
  "titulo": "Introdu√ß√£o ao OpenSearch",
  "conteudo": "OpenSearch √© um fork do Elasticsearch...",
  "autor": "Jo√£o Silva",
  "data_publicacao": "2025-01-15T10:00:00Z",
  "categoria": "Tecnologia",
  "tags": ["opensearch", "busca", "tutorial"],
  "visualizacoes": 0,
  "curtidas": 0,
  "ativo": true
}

# READ
GET http://localhost:9200/blog-posts/_doc/post-001

# UPDATE
POST http://localhost:9200/blog-posts/_update/post-001
Content-Type: application/json

{
  "doc": {
    "visualizacoes": 150
  }
}

# READ novamente
GET http://localhost:9200/blog-posts/_doc/post-001

# DELETE
DELETE http://localhost:9200/blog-posts/_doc/post-001

# READ (not found)
GET http://localhost:9200/blog-posts/_doc/post-001
```

### Exerc√≠cio 2.3: Testando Diferentes Analyzers

**Objetivo**: Compreender o impacto de analyzers na tokeniza√ß√£o.

**Tarefa:**
1. Crie um √≠ndice `analyzer-test` com dois campos:
   - `texto_standard` (usando analyzer padr√£o)
   - `texto_portuguese` (usando analyzer portugu√™s)
2. Insira um documento com texto em portugu√™s
3. Use a API de an√°lise para ver como cada analyzer processa o texto

**Teste de an√°lise:**

```bash
POST http://localhost:9200/analyzer-test/_analyze
Content-Type: application/json

{
  "analyzer": "standard",
  "text": "O r√°pido raposa marrom pulou sobre a cerca"
}
```

**Resultado:**
```json
{
  "tokens": [
    {"token":"o","start_offset":0,"end_offset":1,"type":"<ALPHANUM>","position":0},
    {"token":"r√°pido","start_offset":2,"end_offset":8,"type":"<ALPHANUM>","position":1},
    {"token":"raposa","start_offset":9,"end_offset":15,"type":"<ALPHANUM>","position":2},
    {"token":"marrom","start_offset":16,"end_offset":22,"type":"<ALPHANUM>","position":3},
    {"token":"pulou","start_offset":23,"end_offset":28,"type":"<ALPHANUM>","position":4},
    {"token":"sobre","start_offset":29,"end_offset":34,"type":"<ALPHANUM>","position":5},
    {"token":"a","start_offset":35,"end_offset":36,"type":"<ALPHANUM>","position":6},
    {"token":"cerca","start_offset":37,"end_offset":42,"type":"<ALPHANUM>","position":7}
  ]
}
```

```bash
POST http://localhost:9200/analyzer-test/_analyze
Content-Type: application/json

{
  "analyzer": "portuguese",
  "text": "O r√°pido raposa marrom pulou sobre a cerca"
}
```

**Resultado (note a remo√ß√£o de stopwords):**
```json
{
  "tokens": [
    {"token":"r√°pid","start_offset":2,"end_offset":8,"type":"<ALPHANUM>","position":1},
    {"token":"rapos","start_offset":9,"end_offset":15,"type":"<ALPHANUM>","position":2},
    {"token":"marrom","start_offset":16,"end_offset":22,"type":"<ALPHANUM>","position":3},
    {"token":"pul","start_offset":23,"end_offset":28,"type":"<ALPHANUM>","position":4},
    {"token":"sobr","start_offset":29,"end_offset":34,"type":"<ALPHANUM>","position":5},
    {"token":"cerc","start_offset":37,"end_offset":42,"type":"<ALPHANUM>","position":7}
  ]
}
```

---

## 2.8 S√çNTESE DO CAP√çTULO

Neste cap√≠tulo, voc√™ aprendeu os fundamentos essenciais do OpenSearch:

**Estrutura de dados:**
- √çndices s√£o contineres de documentos
- Documentos s√£o objetos JSON com metadados
- OpenSearch suporta diversos tipos de dados para diferentes necessidades

**Mapeamento:**
- Mapping din√¢mico oferece flexibilidade mas com riscos
- Mapping expl√≠cito √© recomendado para produ√ß√£o
- Multi-campos permitem diferentes tipos de busca no mesmo dado

**An√°lise e tokeniza√ß√£o:**
- Analyzers processam texto em tokens para indexa√ß√£o
- Escolher o analyzer correto impacta qualidade de busca
- Language analyzers espec√≠ficos melhoram resultados em portugu√™s

**Inverted Index:**
- Mapeia termos ‚Üí documentos para busca r√°pida
- TF-IDF calcula relev√¢ncia dos resultados
- Shards distribuem dados para escalabilidade

**Opera√ß√µes CRUD:**
- CREATE: Inserir novos documentos
- READ: Recuperar por ID
- UPDATE: Modificar campos existentes
- DELETE: Remover documentos
- Bulk: Opera√ß√µes em massa eficientemente

Voc√™ agora possui os conhecimentos necess√°rios para estruturar dados, criar √≠ndices apropriados e realizar opera√ß√µes b√°sicas de manipula√ß√£o de dados no OpenSearch. No pr√≥ximo cap√≠tulo, exploraremos como buscar e analisar dados com queries avan√ßadas.

---

## REFER√äNCIAS

OPENSEARCH PROJECT. OpenSearch Documentation: Data Types. Dispon√≠vel em: https://docs.opensearch.org/latest/clients/data/. Acesso em: 15 jan. 2025.

OPENSEARCH PROJECT. OpenSearch Documentation: Mapping. Dispon√≠vel em: https://docs.opensearch.org/latest/field-types/index/. Acesso em: 15 jan. 2025.

OPENSEARCH PROJECT. OpenSearch Documentation: Analyzers. Dispon√≠vel em: https://docs.opensearch.org/latest/analyzers/token-analyzers/. Acesso em: 15 jan. 2025.

OPENSEARCH PROJECT. OpenSearch Documentation: Document API. Dispon√≠vel em: https://docs.opensearch.org/latest/api-reference/document-apis/index/. Acesso em: 15 jan. 2025.

---

**Fim do Cap√≠tulo 2**